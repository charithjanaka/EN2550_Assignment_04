{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EN2550_Assignment_04_P3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9De8aGvcR6EB",
        "outputId": "0a10f90c-0bfb-49fe-fb51-01c694645a5a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loading Training and Test data sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "print('x_train: ', x_train.shape)\n",
        "\n",
        "K = len(np.unique(y_train)) # Number of Classes\n",
        "Ntr = x_train.shape[0]      # Number of Training examples\n",
        "Nte = x_test.shape[0]       # Number of Testing examples\n",
        "Din = 3072                  # CIFAR10 (Size of an example)\n",
        "\n",
        "# Normalize pixel values\n",
        "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Subtract the means of images to make the network less sensitive to differing background and lightening conditions.\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train = x_train - mean_image\n",
        "x_test = x_test - mean_image\n",
        "\n",
        "# Obtaining a binary numpy array from y_train and y_test\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
        "\n",
        "# Reshape image arrays from 32 x 32 x 3 into 1 x  3072\n",
        "x_train = np.reshape(x_train,(Ntr,Din)).astype('float32')\n",
        "x_test = np.reshape(x_test,(Nte,Din)).astype('float32')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train:  (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpbl4Y7mSBaf",
        "outputId": "41ab38df-dff6-432c-dc75-7cd9061689ae"
      },
      "source": [
        "H = 200                               # Number of hidden nodes\n",
        "std=1e-5                              # Standard deviation\n",
        "w1 = std*np.random.randn(Din, H)      # Weights 1 matrix\n",
        "w2 = std*np.random.randn(H, K)        # Weights 2 matrix\n",
        "b1 = np.zeros(H)                      # Bias 1 vector\n",
        "b2 = np.zeros(K)                      # Bias 2 vector\n",
        "print(\"w1:\", w1.shape)\n",
        "print(\"b1:\", b1.shape)\n",
        "print(\"w2:\", w1.shape)\n",
        "print(\"b2:\", b1.shape)\n",
        "\n",
        "batch_size = 500                    # Batch size\n",
        "\n",
        "iterations = 5000                   # Number of iterations to run Gradient Descent (For this case it equals to 300 epochs)\n",
        "alpha = 1.5e-2                        # Learning Rate\n",
        "alpha_decay= 0.999                  # Decay learning rate for convergence\n",
        "Lambda = 5e-6                       # Regularization rate\n",
        "\n",
        "loss_history = []                   # Loss history\n",
        "train_acc_history = []              # Traing accuracy history\n",
        "\n",
        "for t in range(iterations):\n",
        "    indices = np.random.choice(x_train.shape[0], batch_size, replace=False) \n",
        "    # Forward pass\n",
        "    x = x_train[indices]\n",
        "    y = y_train[indices]\n",
        "    h = 1.0/(1.0+np.exp(-(x.dot(w1) + b1)))\n",
        "    y_pred = h.dot(w2) + b2\n",
        "    loss = (1./batch_size)*(np.square(y_pred - y).sum()) + Lambda * (np.sum(w1 * w1) + np.sum(w1 * w1))\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    # Printing Loss in each 10 iterations\n",
        "    if t % 10 == 0:\n",
        "        print('iteration %d / %d: loss %f ' %(t, iterations, loss))\n",
        "\n",
        "    # Backward pass\n",
        "    dy_pred = (1./batch_size)*2.0*(y_pred - y)              # PD of loss w.r.t. y_pred\n",
        "    dw2 = h.T.dot(dy_pred) + Lambda * w2                    # PD of loss w.r.t. w2\n",
        "    db2 = dy_pred.sum(axis = 0)                             # PD of loss w.r.t. b2\n",
        "    dh = dy_pred.dot(w2.T)                                  # PD of loss w.r.t. h\n",
        "    dw1 = x.T.dot(dh*h*(1-h)) + Lambda * w1                 # PD of loss w.r.t. w1 \n",
        "    db1 = (dh*h*(1-h)).sum(axis = 0)                        # PD of loss w.r.t. b1\n",
        "    w2 -= alpha * dw2                                       # Update weights 2\n",
        "    b2 -= alpha * db2                                       # Update biases 2\n",
        "    w1 -= alpha * dw1                                       # Update weights 1\n",
        "    b1 -= alpha * db1                                       # Update biases 1\n",
        "    alpha *= alpha_decay                                    # Decay learning rate\n",
        "\n",
        "    # Appending Train accuracy to history\n",
        "    h = 1.0/(1.0 + np.exp(-(x.dot(w1)+b1)))\n",
        "    y_pred = h.dot(w2) + b2\n",
        "    train_acc = 1.0 - 1/(Ntr*9)*(np.abs(np.argmax(y, axis = 1) - np.argmax(y_pred, axis = 1))).sum()\n",
        "    train_acc_history.append(train_acc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w1: (3072, 200)\n",
            "b1: (200,)\n",
            "w2: (3072, 200)\n",
            "b2: (200,)\n",
            "iteration 0 / 5000: loss 1.000041 \n",
            "iteration 10 / 5000: loss 0.873075 \n",
            "iteration 20 / 5000: loss 0.845695 \n",
            "iteration 30 / 5000: loss 0.836887 \n",
            "iteration 40 / 5000: loss 0.826940 \n",
            "iteration 50 / 5000: loss 0.819518 \n",
            "iteration 60 / 5000: loss 0.801461 \n",
            "iteration 70 / 5000: loss 0.797957 \n",
            "iteration 80 / 5000: loss 0.815303 \n",
            "iteration 90 / 5000: loss 0.783179 \n",
            "iteration 100 / 5000: loss 0.783629 \n",
            "iteration 110 / 5000: loss 0.794827 \n",
            "iteration 120 / 5000: loss 0.785397 \n",
            "iteration 130 / 5000: loss 0.798519 \n",
            "iteration 140 / 5000: loss 0.789430 \n",
            "iteration 150 / 5000: loss 0.786492 \n",
            "iteration 160 / 5000: loss 0.752916 \n",
            "iteration 170 / 5000: loss 0.775624 \n",
            "iteration 180 / 5000: loss 0.791389 \n",
            "iteration 190 / 5000: loss 0.762569 \n",
            "iteration 200 / 5000: loss 0.752748 \n",
            "iteration 210 / 5000: loss 0.776620 \n",
            "iteration 220 / 5000: loss 0.777103 \n",
            "iteration 230 / 5000: loss 0.767756 \n",
            "iteration 240 / 5000: loss 0.768157 \n",
            "iteration 250 / 5000: loss 0.769471 \n",
            "iteration 260 / 5000: loss 0.758163 \n",
            "iteration 270 / 5000: loss 0.751107 \n",
            "iteration 280 / 5000: loss 0.740642 \n",
            "iteration 290 / 5000: loss 0.762723 \n",
            "iteration 300 / 5000: loss 0.762828 \n",
            "iteration 310 / 5000: loss 0.743931 \n",
            "iteration 320 / 5000: loss 0.751885 \n",
            "iteration 330 / 5000: loss 0.743264 \n",
            "iteration 340 / 5000: loss 0.741809 \n",
            "iteration 350 / 5000: loss 0.743180 \n",
            "iteration 360 / 5000: loss 0.732226 \n",
            "iteration 370 / 5000: loss 0.748204 \n",
            "iteration 380 / 5000: loss 0.752802 \n",
            "iteration 390 / 5000: loss 0.762466 \n",
            "iteration 400 / 5000: loss 0.753786 \n",
            "iteration 410 / 5000: loss 0.735862 \n",
            "iteration 420 / 5000: loss 0.738128 \n",
            "iteration 430 / 5000: loss 0.718113 \n",
            "iteration 440 / 5000: loss 0.737134 \n",
            "iteration 450 / 5000: loss 0.732243 \n",
            "iteration 460 / 5000: loss 0.736264 \n",
            "iteration 470 / 5000: loss 0.721093 \n",
            "iteration 480 / 5000: loss 0.745424 \n",
            "iteration 490 / 5000: loss 0.744427 \n",
            "iteration 500 / 5000: loss 0.729719 \n",
            "iteration 510 / 5000: loss 0.735936 \n",
            "iteration 520 / 5000: loss 0.731744 \n",
            "iteration 530 / 5000: loss 0.736859 \n",
            "iteration 540 / 5000: loss 0.717318 \n",
            "iteration 550 / 5000: loss 0.708393 \n",
            "iteration 560 / 5000: loss 0.715731 \n",
            "iteration 570 / 5000: loss 0.703160 \n",
            "iteration 580 / 5000: loss 0.717090 \n",
            "iteration 590 / 5000: loss 0.729188 \n",
            "iteration 600 / 5000: loss 0.725918 \n",
            "iteration 610 / 5000: loss 0.730303 \n",
            "iteration 620 / 5000: loss 0.715803 \n",
            "iteration 630 / 5000: loss 0.723024 \n",
            "iteration 640 / 5000: loss 0.723801 \n",
            "iteration 650 / 5000: loss 0.699611 \n",
            "iteration 660 / 5000: loss 0.705574 \n",
            "iteration 670 / 5000: loss 0.721819 \n",
            "iteration 680 / 5000: loss 0.705658 \n",
            "iteration 690 / 5000: loss 0.700507 \n",
            "iteration 700 / 5000: loss 0.705201 \n",
            "iteration 710 / 5000: loss 0.706291 \n",
            "iteration 720 / 5000: loss 0.710177 \n",
            "iteration 730 / 5000: loss 0.710125 \n",
            "iteration 740 / 5000: loss 0.696710 \n",
            "iteration 750 / 5000: loss 0.713459 \n",
            "iteration 760 / 5000: loss 0.680562 \n",
            "iteration 770 / 5000: loss 0.698820 \n",
            "iteration 780 / 5000: loss 0.713104 \n",
            "iteration 790 / 5000: loss 0.692626 \n",
            "iteration 800 / 5000: loss 0.703343 \n",
            "iteration 810 / 5000: loss 0.693937 \n",
            "iteration 820 / 5000: loss 0.712096 \n",
            "iteration 830 / 5000: loss 0.701474 \n",
            "iteration 840 / 5000: loss 0.692600 \n",
            "iteration 850 / 5000: loss 0.696297 \n",
            "iteration 860 / 5000: loss 0.712553 \n",
            "iteration 870 / 5000: loss 0.671669 \n",
            "iteration 880 / 5000: loss 0.711386 \n",
            "iteration 890 / 5000: loss 0.684858 \n",
            "iteration 900 / 5000: loss 0.691797 \n",
            "iteration 910 / 5000: loss 0.689980 \n",
            "iteration 920 / 5000: loss 0.708940 \n",
            "iteration 930 / 5000: loss 0.689420 \n",
            "iteration 940 / 5000: loss 0.671285 \n",
            "iteration 950 / 5000: loss 0.703125 \n",
            "iteration 960 / 5000: loss 0.682372 \n",
            "iteration 970 / 5000: loss 0.696128 \n",
            "iteration 980 / 5000: loss 0.689432 \n",
            "iteration 990 / 5000: loss 0.704763 \n",
            "iteration 1000 / 5000: loss 0.690718 \n",
            "iteration 1010 / 5000: loss 0.692008 \n",
            "iteration 1020 / 5000: loss 0.685666 \n",
            "iteration 1030 / 5000: loss 0.674160 \n",
            "iteration 1040 / 5000: loss 0.689986 \n",
            "iteration 1050 / 5000: loss 0.699062 \n",
            "iteration 1060 / 5000: loss 0.684916 \n",
            "iteration 1070 / 5000: loss 0.680240 \n",
            "iteration 1080 / 5000: loss 0.690017 \n",
            "iteration 1090 / 5000: loss 0.688511 \n",
            "iteration 1100 / 5000: loss 0.673490 \n",
            "iteration 1110 / 5000: loss 0.705402 \n",
            "iteration 1120 / 5000: loss 0.658102 \n",
            "iteration 1130 / 5000: loss 0.683839 \n",
            "iteration 1140 / 5000: loss 0.662021 \n",
            "iteration 1150 / 5000: loss 0.669396 \n",
            "iteration 1160 / 5000: loss 0.664571 \n",
            "iteration 1170 / 5000: loss 0.681466 \n",
            "iteration 1180 / 5000: loss 0.677045 \n",
            "iteration 1190 / 5000: loss 0.669256 \n",
            "iteration 1200 / 5000: loss 0.688592 \n",
            "iteration 1210 / 5000: loss 0.662217 \n",
            "iteration 1220 / 5000: loss 0.659820 \n",
            "iteration 1230 / 5000: loss 0.670319 \n",
            "iteration 1240 / 5000: loss 0.681643 \n",
            "iteration 1250 / 5000: loss 0.662017 \n",
            "iteration 1260 / 5000: loss 0.671028 \n",
            "iteration 1270 / 5000: loss 0.655210 \n",
            "iteration 1280 / 5000: loss 0.650725 \n",
            "iteration 1290 / 5000: loss 0.670803 \n",
            "iteration 1300 / 5000: loss 0.680445 \n",
            "iteration 1310 / 5000: loss 0.665827 \n",
            "iteration 1320 / 5000: loss 0.646564 \n",
            "iteration 1330 / 5000: loss 0.670283 \n",
            "iteration 1340 / 5000: loss 0.668674 \n",
            "iteration 1350 / 5000: loss 0.663334 \n",
            "iteration 1360 / 5000: loss 0.665758 \n",
            "iteration 1370 / 5000: loss 0.638276 \n",
            "iteration 1380 / 5000: loss 0.667550 \n",
            "iteration 1390 / 5000: loss 0.671675 \n",
            "iteration 1400 / 5000: loss 0.685902 \n",
            "iteration 1410 / 5000: loss 0.666736 \n",
            "iteration 1420 / 5000: loss 0.634508 \n",
            "iteration 1430 / 5000: loss 0.668566 \n",
            "iteration 1440 / 5000: loss 0.665353 \n",
            "iteration 1450 / 5000: loss 0.663180 \n",
            "iteration 1460 / 5000: loss 0.650274 \n",
            "iteration 1470 / 5000: loss 0.655066 \n",
            "iteration 1480 / 5000: loss 0.646900 \n",
            "iteration 1490 / 5000: loss 0.651527 \n",
            "iteration 1500 / 5000: loss 0.654404 \n",
            "iteration 1510 / 5000: loss 0.659393 \n",
            "iteration 1520 / 5000: loss 0.648460 \n",
            "iteration 1530 / 5000: loss 0.666751 \n",
            "iteration 1540 / 5000: loss 0.644349 \n",
            "iteration 1550 / 5000: loss 0.644086 \n",
            "iteration 1560 / 5000: loss 0.639325 \n",
            "iteration 1570 / 5000: loss 0.627719 \n",
            "iteration 1580 / 5000: loss 0.638968 \n",
            "iteration 1590 / 5000: loss 0.652853 \n",
            "iteration 1600 / 5000: loss 0.636268 \n",
            "iteration 1610 / 5000: loss 0.667340 \n",
            "iteration 1620 / 5000: loss 0.637834 \n",
            "iteration 1630 / 5000: loss 0.659529 \n",
            "iteration 1640 / 5000: loss 0.602333 \n",
            "iteration 1650 / 5000: loss 0.631899 \n",
            "iteration 1660 / 5000: loss 0.619148 \n",
            "iteration 1670 / 5000: loss 0.633543 \n",
            "iteration 1680 / 5000: loss 0.634429 \n",
            "iteration 1690 / 5000: loss 0.656057 \n",
            "iteration 1700 / 5000: loss 0.636252 \n",
            "iteration 1710 / 5000: loss 0.644910 \n",
            "iteration 1720 / 5000: loss 0.638776 \n",
            "iteration 1730 / 5000: loss 0.647402 \n",
            "iteration 1740 / 5000: loss 0.655543 \n",
            "iteration 1750 / 5000: loss 0.640866 \n",
            "iteration 1760 / 5000: loss 0.646878 \n",
            "iteration 1770 / 5000: loss 0.642454 \n",
            "iteration 1780 / 5000: loss 0.631645 \n",
            "iteration 1790 / 5000: loss 0.653857 \n",
            "iteration 1800 / 5000: loss 0.655249 \n",
            "iteration 1810 / 5000: loss 0.620704 \n",
            "iteration 1820 / 5000: loss 0.646272 \n",
            "iteration 1830 / 5000: loss 0.656227 \n",
            "iteration 1840 / 5000: loss 0.625801 \n",
            "iteration 1850 / 5000: loss 0.627008 \n",
            "iteration 1860 / 5000: loss 0.654832 \n",
            "iteration 1870 / 5000: loss 0.633576 \n",
            "iteration 1880 / 5000: loss 0.606792 \n",
            "iteration 1890 / 5000: loss 0.623702 \n",
            "iteration 1900 / 5000: loss 0.634974 \n",
            "iteration 1910 / 5000: loss 0.637727 \n",
            "iteration 1920 / 5000: loss 0.639288 \n",
            "iteration 1930 / 5000: loss 0.638083 \n",
            "iteration 1940 / 5000: loss 0.618164 \n",
            "iteration 1950 / 5000: loss 0.627073 \n",
            "iteration 1960 / 5000: loss 0.624071 \n",
            "iteration 1970 / 5000: loss 0.646167 \n",
            "iteration 1980 / 5000: loss 0.606175 \n",
            "iteration 1990 / 5000: loss 0.607568 \n",
            "iteration 2000 / 5000: loss 0.655008 \n",
            "iteration 2010 / 5000: loss 0.615644 \n",
            "iteration 2020 / 5000: loss 0.638209 \n",
            "iteration 2030 / 5000: loss 0.632860 \n",
            "iteration 2040 / 5000: loss 0.628224 \n",
            "iteration 2050 / 5000: loss 0.627858 \n",
            "iteration 2060 / 5000: loss 0.601299 \n",
            "iteration 2070 / 5000: loss 0.604722 \n",
            "iteration 2080 / 5000: loss 0.635691 \n",
            "iteration 2090 / 5000: loss 0.623621 \n",
            "iteration 2100 / 5000: loss 0.636242 \n",
            "iteration 2110 / 5000: loss 0.626111 \n",
            "iteration 2120 / 5000: loss 0.639328 \n",
            "iteration 2130 / 5000: loss 0.618088 \n",
            "iteration 2140 / 5000: loss 0.620852 \n",
            "iteration 2150 / 5000: loss 0.663939 \n",
            "iteration 2160 / 5000: loss 0.630463 \n",
            "iteration 2170 / 5000: loss 0.623907 \n",
            "iteration 2180 / 5000: loss 0.601899 \n",
            "iteration 2190 / 5000: loss 0.635308 \n",
            "iteration 2200 / 5000: loss 0.609088 \n",
            "iteration 2210 / 5000: loss 0.640321 \n",
            "iteration 2220 / 5000: loss 0.620361 \n",
            "iteration 2230 / 5000: loss 0.613007 \n",
            "iteration 2240 / 5000: loss 0.619447 \n",
            "iteration 2250 / 5000: loss 0.597392 \n",
            "iteration 2260 / 5000: loss 0.622362 \n",
            "iteration 2270 / 5000: loss 0.609106 \n",
            "iteration 2280 / 5000: loss 0.604564 \n",
            "iteration 2290 / 5000: loss 0.628176 \n",
            "iteration 2300 / 5000: loss 0.634455 \n",
            "iteration 2310 / 5000: loss 0.622375 \n",
            "iteration 2320 / 5000: loss 0.621396 \n",
            "iteration 2330 / 5000: loss 0.614517 \n",
            "iteration 2340 / 5000: loss 0.608964 \n",
            "iteration 2350 / 5000: loss 0.632596 \n",
            "iteration 2360 / 5000: loss 0.607581 \n",
            "iteration 2370 / 5000: loss 0.601392 \n",
            "iteration 2380 / 5000: loss 0.613204 \n",
            "iteration 2390 / 5000: loss 0.598277 \n",
            "iteration 2400 / 5000: loss 0.610828 \n",
            "iteration 2410 / 5000: loss 0.586720 \n",
            "iteration 2420 / 5000: loss 0.622943 \n",
            "iteration 2430 / 5000: loss 0.606059 \n",
            "iteration 2440 / 5000: loss 0.610130 \n",
            "iteration 2450 / 5000: loss 0.597773 \n",
            "iteration 2460 / 5000: loss 0.595587 \n",
            "iteration 2470 / 5000: loss 0.613271 \n",
            "iteration 2480 / 5000: loss 0.608359 \n",
            "iteration 2490 / 5000: loss 0.617484 \n",
            "iteration 2500 / 5000: loss 0.617538 \n",
            "iteration 2510 / 5000: loss 0.644583 \n",
            "iteration 2520 / 5000: loss 0.602253 \n",
            "iteration 2530 / 5000: loss 0.612398 \n",
            "iteration 2540 / 5000: loss 0.601678 \n",
            "iteration 2550 / 5000: loss 0.626626 \n",
            "iteration 2560 / 5000: loss 0.595578 \n",
            "iteration 2570 / 5000: loss 0.611853 \n",
            "iteration 2580 / 5000: loss 0.619696 \n",
            "iteration 2590 / 5000: loss 0.626024 \n",
            "iteration 2600 / 5000: loss 0.608361 \n",
            "iteration 2610 / 5000: loss 0.605972 \n",
            "iteration 2620 / 5000: loss 0.599198 \n",
            "iteration 2630 / 5000: loss 0.600384 \n",
            "iteration 2640 / 5000: loss 0.596349 \n",
            "iteration 2650 / 5000: loss 0.631097 \n",
            "iteration 2660 / 5000: loss 0.627024 \n",
            "iteration 2670 / 5000: loss 0.601762 \n",
            "iteration 2680 / 5000: loss 0.628278 \n",
            "iteration 2690 / 5000: loss 0.606164 \n",
            "iteration 2700 / 5000: loss 0.612496 \n",
            "iteration 2710 / 5000: loss 0.604359 \n",
            "iteration 2720 / 5000: loss 0.623629 \n",
            "iteration 2730 / 5000: loss 0.606371 \n",
            "iteration 2740 / 5000: loss 0.620732 \n",
            "iteration 2750 / 5000: loss 0.587310 \n",
            "iteration 2760 / 5000: loss 0.590678 \n",
            "iteration 2770 / 5000: loss 0.611506 \n",
            "iteration 2780 / 5000: loss 0.598486 \n",
            "iteration 2790 / 5000: loss 0.583090 \n",
            "iteration 2800 / 5000: loss 0.597242 \n",
            "iteration 2810 / 5000: loss 0.626141 \n",
            "iteration 2820 / 5000: loss 0.595554 \n",
            "iteration 2830 / 5000: loss 0.622021 \n",
            "iteration 2840 / 5000: loss 0.608678 \n",
            "iteration 2850 / 5000: loss 0.602093 \n",
            "iteration 2860 / 5000: loss 0.587548 \n",
            "iteration 2870 / 5000: loss 0.603850 \n",
            "iteration 2880 / 5000: loss 0.600701 \n",
            "iteration 2890 / 5000: loss 0.598755 \n",
            "iteration 2900 / 5000: loss 0.604582 \n",
            "iteration 2910 / 5000: loss 0.608501 \n",
            "iteration 2920 / 5000: loss 0.603880 \n",
            "iteration 2930 / 5000: loss 0.606692 \n",
            "iteration 2940 / 5000: loss 0.589697 \n",
            "iteration 2950 / 5000: loss 0.580917 \n",
            "iteration 2960 / 5000: loss 0.602796 \n",
            "iteration 2970 / 5000: loss 0.602004 \n",
            "iteration 2980 / 5000: loss 0.600264 \n",
            "iteration 2990 / 5000: loss 0.596480 \n",
            "iteration 3000 / 5000: loss 0.592211 \n",
            "iteration 3010 / 5000: loss 0.600565 \n",
            "iteration 3020 / 5000: loss 0.599281 \n",
            "iteration 3030 / 5000: loss 0.585914 \n",
            "iteration 3040 / 5000: loss 0.595248 \n",
            "iteration 3050 / 5000: loss 0.584840 \n",
            "iteration 3060 / 5000: loss 0.595106 \n",
            "iteration 3070 / 5000: loss 0.606395 \n",
            "iteration 3080 / 5000: loss 0.607321 \n",
            "iteration 3090 / 5000: loss 0.606674 \n",
            "iteration 3100 / 5000: loss 0.586527 \n",
            "iteration 3110 / 5000: loss 0.627750 \n",
            "iteration 3120 / 5000: loss 0.605133 \n",
            "iteration 3130 / 5000: loss 0.591400 \n",
            "iteration 3140 / 5000: loss 0.609820 \n",
            "iteration 3150 / 5000: loss 0.609947 \n",
            "iteration 3160 / 5000: loss 0.618737 \n",
            "iteration 3170 / 5000: loss 0.611916 \n",
            "iteration 3180 / 5000: loss 0.598810 \n",
            "iteration 3190 / 5000: loss 0.594633 \n",
            "iteration 3200 / 5000: loss 0.612793 \n",
            "iteration 3210 / 5000: loss 0.593971 \n",
            "iteration 3220 / 5000: loss 0.599698 \n",
            "iteration 3230 / 5000: loss 0.607470 \n",
            "iteration 3240 / 5000: loss 0.594294 \n",
            "iteration 3250 / 5000: loss 0.585558 \n",
            "iteration 3260 / 5000: loss 0.614919 \n",
            "iteration 3270 / 5000: loss 0.604601 \n",
            "iteration 3280 / 5000: loss 0.590535 \n",
            "iteration 3290 / 5000: loss 0.610751 \n",
            "iteration 3300 / 5000: loss 0.605618 \n",
            "iteration 3310 / 5000: loss 0.598515 \n",
            "iteration 3320 / 5000: loss 0.595682 \n",
            "iteration 3330 / 5000: loss 0.572532 \n",
            "iteration 3340 / 5000: loss 0.603094 \n",
            "iteration 3350 / 5000: loss 0.596605 \n",
            "iteration 3360 / 5000: loss 0.589152 \n",
            "iteration 3370 / 5000: loss 0.583083 \n",
            "iteration 3380 / 5000: loss 0.583487 \n",
            "iteration 3390 / 5000: loss 0.591773 \n",
            "iteration 3400 / 5000: loss 0.608119 \n",
            "iteration 3410 / 5000: loss 0.587624 \n",
            "iteration 3420 / 5000: loss 0.607081 \n",
            "iteration 3430 / 5000: loss 0.586814 \n",
            "iteration 3440 / 5000: loss 0.582668 \n",
            "iteration 3450 / 5000: loss 0.592444 \n",
            "iteration 3460 / 5000: loss 0.586691 \n",
            "iteration 3470 / 5000: loss 0.582674 \n",
            "iteration 3480 / 5000: loss 0.617757 \n",
            "iteration 3490 / 5000: loss 0.598531 \n",
            "iteration 3500 / 5000: loss 0.582092 \n",
            "iteration 3510 / 5000: loss 0.612071 \n",
            "iteration 3520 / 5000: loss 0.573515 \n",
            "iteration 3530 / 5000: loss 0.570687 \n",
            "iteration 3540 / 5000: loss 0.583158 \n",
            "iteration 3550 / 5000: loss 0.609636 \n",
            "iteration 3560 / 5000: loss 0.573255 \n",
            "iteration 3570 / 5000: loss 0.596507 \n",
            "iteration 3580 / 5000: loss 0.587267 \n",
            "iteration 3590 / 5000: loss 0.573199 \n",
            "iteration 3600 / 5000: loss 0.598329 \n",
            "iteration 3610 / 5000: loss 0.583667 \n",
            "iteration 3620 / 5000: loss 0.603173 \n",
            "iteration 3630 / 5000: loss 0.583637 \n",
            "iteration 3640 / 5000: loss 0.608586 \n",
            "iteration 3650 / 5000: loss 0.588823 \n",
            "iteration 3660 / 5000: loss 0.579077 \n",
            "iteration 3670 / 5000: loss 0.583629 \n",
            "iteration 3680 / 5000: loss 0.599070 \n",
            "iteration 3690 / 5000: loss 0.556549 \n",
            "iteration 3700 / 5000: loss 0.596225 \n",
            "iteration 3710 / 5000: loss 0.603869 \n",
            "iteration 3720 / 5000: loss 0.588843 \n",
            "iteration 3730 / 5000: loss 0.580601 \n",
            "iteration 3740 / 5000: loss 0.589688 \n",
            "iteration 3750 / 5000: loss 0.577931 \n",
            "iteration 3760 / 5000: loss 0.596963 \n",
            "iteration 3770 / 5000: loss 0.577431 \n",
            "iteration 3780 / 5000: loss 0.601922 \n",
            "iteration 3790 / 5000: loss 0.603402 \n",
            "iteration 3800 / 5000: loss 0.609842 \n",
            "iteration 3810 / 5000: loss 0.593815 \n",
            "iteration 3820 / 5000: loss 0.574420 \n",
            "iteration 3830 / 5000: loss 0.584945 \n",
            "iteration 3840 / 5000: loss 0.593699 \n",
            "iteration 3850 / 5000: loss 0.586744 \n",
            "iteration 3860 / 5000: loss 0.606304 \n",
            "iteration 3870 / 5000: loss 0.582481 \n",
            "iteration 3880 / 5000: loss 0.582013 \n",
            "iteration 3890 / 5000: loss 0.592031 \n",
            "iteration 3900 / 5000: loss 0.606210 \n",
            "iteration 3910 / 5000: loss 0.582865 \n",
            "iteration 3920 / 5000: loss 0.551098 \n",
            "iteration 3930 / 5000: loss 0.591883 \n",
            "iteration 3940 / 5000: loss 0.583857 \n",
            "iteration 3950 / 5000: loss 0.598522 \n",
            "iteration 3960 / 5000: loss 0.588865 \n",
            "iteration 3970 / 5000: loss 0.581368 \n",
            "iteration 3980 / 5000: loss 0.582734 \n",
            "iteration 3990 / 5000: loss 0.594813 \n",
            "iteration 4000 / 5000: loss 0.589751 \n",
            "iteration 4010 / 5000: loss 0.583105 \n",
            "iteration 4020 / 5000: loss 0.610444 \n",
            "iteration 4030 / 5000: loss 0.581981 \n",
            "iteration 4040 / 5000: loss 0.612132 \n",
            "iteration 4050 / 5000: loss 0.596024 \n",
            "iteration 4060 / 5000: loss 0.600832 \n",
            "iteration 4070 / 5000: loss 0.590021 \n",
            "iteration 4080 / 5000: loss 0.564615 \n",
            "iteration 4090 / 5000: loss 0.593780 \n",
            "iteration 4100 / 5000: loss 0.588044 \n",
            "iteration 4110 / 5000: loss 0.602935 \n",
            "iteration 4120 / 5000: loss 0.590008 \n",
            "iteration 4130 / 5000: loss 0.611121 \n",
            "iteration 4140 / 5000: loss 0.602974 \n",
            "iteration 4150 / 5000: loss 0.573298 \n",
            "iteration 4160 / 5000: loss 0.581063 \n",
            "iteration 4170 / 5000: loss 0.576093 \n",
            "iteration 4180 / 5000: loss 0.604050 \n",
            "iteration 4190 / 5000: loss 0.575620 \n",
            "iteration 4200 / 5000: loss 0.590510 \n",
            "iteration 4210 / 5000: loss 0.595177 \n",
            "iteration 4220 / 5000: loss 0.583058 \n",
            "iteration 4230 / 5000: loss 0.610097 \n",
            "iteration 4240 / 5000: loss 0.580664 \n",
            "iteration 4250 / 5000: loss 0.581412 \n",
            "iteration 4260 / 5000: loss 0.571838 \n",
            "iteration 4270 / 5000: loss 0.586034 \n",
            "iteration 4280 / 5000: loss 0.584626 \n",
            "iteration 4290 / 5000: loss 0.587680 \n",
            "iteration 4300 / 5000: loss 0.580906 \n",
            "iteration 4310 / 5000: loss 0.613566 \n",
            "iteration 4320 / 5000: loss 0.613946 \n",
            "iteration 4330 / 5000: loss 0.578824 \n",
            "iteration 4340 / 5000: loss 0.581963 \n",
            "iteration 4350 / 5000: loss 0.601620 \n",
            "iteration 4360 / 5000: loss 0.593102 \n",
            "iteration 4370 / 5000: loss 0.589352 \n",
            "iteration 4380 / 5000: loss 0.575032 \n",
            "iteration 4390 / 5000: loss 0.569846 \n",
            "iteration 4400 / 5000: loss 0.577799 \n",
            "iteration 4410 / 5000: loss 0.590163 \n",
            "iteration 4420 / 5000: loss 0.604292 \n",
            "iteration 4430 / 5000: loss 0.602197 \n",
            "iteration 4440 / 5000: loss 0.580884 \n",
            "iteration 4450 / 5000: loss 0.596839 \n",
            "iteration 4460 / 5000: loss 0.578919 \n",
            "iteration 4470 / 5000: loss 0.556068 \n",
            "iteration 4480 / 5000: loss 0.591982 \n",
            "iteration 4490 / 5000: loss 0.574957 \n",
            "iteration 4500 / 5000: loss 0.581760 \n",
            "iteration 4510 / 5000: loss 0.565338 \n",
            "iteration 4520 / 5000: loss 0.576454 \n",
            "iteration 4530 / 5000: loss 0.585621 \n",
            "iteration 4540 / 5000: loss 0.576028 \n",
            "iteration 4550 / 5000: loss 0.591302 \n",
            "iteration 4560 / 5000: loss 0.591573 \n",
            "iteration 4570 / 5000: loss 0.574623 \n",
            "iteration 4580 / 5000: loss 0.595786 \n",
            "iteration 4590 / 5000: loss 0.593474 \n",
            "iteration 4600 / 5000: loss 0.605413 \n",
            "iteration 4610 / 5000: loss 0.593935 \n",
            "iteration 4620 / 5000: loss 0.598394 \n",
            "iteration 4630 / 5000: loss 0.591190 \n",
            "iteration 4640 / 5000: loss 0.588614 \n",
            "iteration 4650 / 5000: loss 0.600674 \n",
            "iteration 4660 / 5000: loss 0.593930 \n",
            "iteration 4670 / 5000: loss 0.592900 \n",
            "iteration 4680 / 5000: loss 0.589906 \n",
            "iteration 4690 / 5000: loss 0.596489 \n",
            "iteration 4700 / 5000: loss 0.591027 \n",
            "iteration 4710 / 5000: loss 0.584951 \n",
            "iteration 4720 / 5000: loss 0.590039 \n",
            "iteration 4730 / 5000: loss 0.602005 \n",
            "iteration 4740 / 5000: loss 0.577495 \n",
            "iteration 4750 / 5000: loss 0.580345 \n",
            "iteration 4760 / 5000: loss 0.585575 \n",
            "iteration 4770 / 5000: loss 0.595223 \n",
            "iteration 4780 / 5000: loss 0.589114 \n",
            "iteration 4790 / 5000: loss 0.582173 \n",
            "iteration 4800 / 5000: loss 0.595074 \n",
            "iteration 4810 / 5000: loss 0.581139 \n",
            "iteration 4820 / 5000: loss 0.588591 \n",
            "iteration 4830 / 5000: loss 0.600521 \n",
            "iteration 4840 / 5000: loss 0.571944 \n",
            "iteration 4850 / 5000: loss 0.583155 \n",
            "iteration 4860 / 5000: loss 0.588075 \n",
            "iteration 4870 / 5000: loss 0.557850 \n",
            "iteration 4880 / 5000: loss 0.608411 \n",
            "iteration 4890 / 5000: loss 0.582705 \n",
            "iteration 4900 / 5000: loss 0.592977 \n",
            "iteration 4910 / 5000: loss 0.559807 \n",
            "iteration 4920 / 5000: loss 0.581849 \n",
            "iteration 4930 / 5000: loss 0.582146 \n",
            "iteration 4940 / 5000: loss 0.581908 \n",
            "iteration 4950 / 5000: loss 0.587589 \n",
            "iteration 4960 / 5000: loss 0.591012 \n",
            "iteration 4970 / 5000: loss 0.590004 \n",
            "iteration 4980 / 5000: loss 0.569780 \n",
            "iteration 4990 / 5000: loss 0.585660 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "jZ1aheajSE7D",
        "outputId": "859b85e4-2619-4795-b33a-e34a16bb6f88"
      },
      "source": [
        "# Printing accuracies and losses\n",
        "\n",
        "# History\n",
        "fig, ax = plt.subplots(1,2, figsize = (10,5))\n",
        "ax[0].plot(loss_history)                # Training Loss History\n",
        "ax[1].plot(train_acc_history)           # Training Accuracy History\n",
        "\n",
        "# Calculating and Printing Training Accuracy\n",
        "x_t = x_train\n",
        "h = 1.0/(1.0+np.exp(-(x_t.dot(w1) + b1)))\n",
        "y_pred = h.dot(w2) + b2\n",
        "train_acc = 1.0 - 1/(Ntr*9)*(np.abs(np.argmax(y_train, axis = 1) - np.argmax(y_pred, axis = 1))).sum()\n",
        "print(\"train_acc = \",train_acc)\n",
        "\n",
        "# Calculating and Printing Testing Accuracy\n",
        "x_t = x_test\n",
        "h = 1.0/(1.0+np.exp(-(x_t.dot(w1) + b1)))\n",
        "y_pred = h.dot(w2) + b2\n",
        "test_acc =  1.0 - 1/(Nte*9)*(np.abs(np.argmax(y_test, axis = 1) - np.argmax(y_pred, axis = 1))).sum()\n",
        "print(\"test_acc = \",test_acc)\n",
        "\n",
        "# Testing Loss\n",
        "test_loss = (1./Nte)*(np.square(y_pred - y_test).sum())\n",
        "print(\"test_loss = \",test_loss)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_acc =  0.8694333333333333\n",
            "test_acc =  0.7833444444444444\n",
            "test_loss =  0.7426716751401601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tADy4BGr2udO"
      },
      "source": [
        "Log (Experiment with Alpha)\n",
        "\n",
        "alpha     tr_loss     te_loss      tr_acc     te_acc     ierations\n",
        "\n",
        "2e-3      0.7411      0.7512       0.7815     0.7694     30000\n",
        "\n",
        "5e-3      0.6682      0.7277       0.8225     0.7824     30000\n",
        "\n",
        "5e-3      0.6817      0.7291       0.8219     0.7808     5000\n",
        "\n",
        "1e-2      0.5941      0.7311       0.8555     0.7809     5000\n",
        "\n",
        "1.6e-2    0.5830      0.7421       0.8637     0.7733     5000\n",
        "\n",
        "1.5e-2    0.5744      0.7389       0.8684     0.7812     5000\n",
        "\n",
        "1.4e-2    0.5741      0.7411       0.8684     0.7799     5000      "
      ]
    }
  ]
}